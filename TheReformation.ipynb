{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc037c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANT\n",
    "\n",
    "#because this is a very large website, make sure to run jupyter with: \n",
    "#jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000 \n",
    "#or else it may run out of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861eab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "#\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from time import sleep\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e15f0543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 103.0.5060\n",
      "Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "Driver [C:\\Users\\813ro\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.53\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#Useful example of having the driver scroll down the page slowly to generate any new products if the page gets larger as you scroll\\ntotal_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\\n    i = 1\\n    while i < total_height:\\n        i+=5\\n        total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\\n        driver.execute_script(\"window.scrollTo(0, {});\".format(i))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lists for data\n",
    "\n",
    "brand = [] #\n",
    "product_type = [] #\n",
    "product_name = [] #\n",
    "product_description = []#\n",
    "price = []#\n",
    "sales_price = []#\n",
    "color = [] #reference the wearpact crawler for how to get the image of each different color\n",
    "material = []#\n",
    "product_url = []#\n",
    "picture_url = []# \n",
    "timestamp = []#\n",
    "gender = [] #looks like the site is all womens clothing\n",
    "new_arrival = []#\n",
    "new_arrival_names=[] \n",
    "# you will definitely need to use scrolling loop i used \n",
    "#maybe add a sleep somewhere in there to give it extra time to go down\n",
    "#as it seems you have to fully hit the bottom before it puts new products\n",
    "\n",
    "current_date = date.today()\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install())) #selenium\n",
    "driver.set_window_size(1120, 1000)\n",
    "\n",
    "#to get a webpage with selenium you use driver.get(url), and if you want to crawl what the driver sees using bs4 you use\n",
    "    # soup = BeautifulSoup(driver.page_source,'html.parser'), keep in mind you can also find and access attributes of elements\n",
    "    # with selenium using BY. I used this a few times in mine (needed for clicking)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#Useful example of having the driver scroll down the page slowly to generate any new products if the page gets larger as you scroll\n",
    "total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    i = 1\n",
    "    while i < total_height:\n",
    "        i+=5\n",
    "        total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c078a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting info from product\n",
    "\n",
    "#everything is generated through JS on the page, therefore you cannot use beautiful soup (selenium is needed)\n",
    "def getProductInfo(url):\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    \n",
    "    \n",
    "    #brand (always pact)\n",
    "    prod_brand = \"TheReformation\"\n",
    "    \n",
    "    #name\n",
    "    prod_title_div = soup.find('h1', {'class':'pdp__name'})\n",
    "    if prod_title_div == None:\n",
    "        return None\n",
    "    prod_title = prod_title_div.get_text()\n",
    "    \n",
    "    \n",
    "    #product_type + gender\n",
    "    prod_ol = soup.find('ol', {'class':'breadcrumbs'})\n",
    "    \n",
    "    '''\n",
    "    prod_gender = prod_ol.contents[0].get_text()\n",
    "    if prod_gender == \"baby\":\n",
    "        prod_gender = \"kids\"\n",
    "    '''\n",
    "    prod_gender = \"womens\" #always womens clothing\n",
    "    \n",
    "    prod_type = prod_ol.contents[1].a.get_text()\n",
    "    print(prod_type)\n",
    "    #prices\n",
    "    prod_price = None\n",
    "    prod_sale_price = soup.find('span',{'class':'price--formatted'})\n",
    "    '''\n",
    "    if prod_sale:\n",
    "        prod_bundle = prod_sale.get_text()\n",
    "        price_split = prod_bundle.split('$')\n",
    "        prod_price = '$' + price_split[2]\n",
    "        prod_sale_price = '$' + price_split[1]\n",
    "    else:\n",
    "        prod_sale_price = soup.find('div', {'class':'dollar'}).get_text()\n",
    "    '''\n",
    "    \n",
    "    #desc\n",
    "    desc_sentence = soup.find(\"div\", {'class':'cms-generic-copy'})\n",
    "    print(desc_sentence.get_text())\n",
    "    '''\n",
    "    desc_ul = desc_div.contents[0]\n",
    "    desc_sentence = ''\n",
    "    for child in desc_ul.children:\n",
    "        desc_sentence += child.get_text() + \". \"\n",
    "    '''\n",
    "    #Material (see explanation in previous cell)\n",
    "    prod_material = soup.find(\"div\", {'class':'margin-b--15'})\n",
    "    \n",
    "    \n",
    "    #New Arrival\n",
    "    is_new = prod_title in new_arrival_names\n",
    "    \n",
    "    #color + image url are unique, as they are a different entry but share almost all of the same data (including url)\n",
    "        #therefore this really makes as many entries as there are color options (using clicks from selenium)\n",
    "    #color_list = soup.find('div',{'class':'product-attributes__contents'})\n",
    "    color_list = soup.find_all('div',{'class':'flex-flow-wrap'})[3]\n",
    "    \n",
    "    count = 1\n",
    "    for child in color_list.find_all('button'):\n",
    "        #color name\n",
    "        \n",
    "        prod_color = child.get('title') #color name\n",
    "        \n",
    "        #image url (click with selenium)\n",
    "        color_btn = driver.find_element(By.XPATH, f\"//div[@data-attr-group='color']/div[2]/button[{count}]\")\n",
    "        \n",
    "        color_btn.click()\n",
    "        sleep(1)\n",
    "        image_tag = driver.find_element(By.XPATH, \"//img[@itemprop='image']\")\n",
    "        prod_image_url = image_tag.get_attribute(\"src\")\n",
    "        sleep(1)\n",
    "        \n",
    "        count += 1\n",
    "        #creating df entry\n",
    "        timestamp.append(current_date)\n",
    "        product_url.append(url)\n",
    "        brand.append(prod_brand)\n",
    "        product_name.append(prod_title)\n",
    "        gender.append(prod_gender)\n",
    "        product_type.append(prod_type)\n",
    "        price.append(prod_price)\n",
    "        sales_price.append(prod_sale_price)\n",
    "        product_description.append(desc_sentence)\n",
    "        material.append(prod_material)\n",
    "        new_arrival.append(is_new)\n",
    "        color.append(prod_color)\n",
    "        picture_url.append(prod_image_url)\n",
    "    \n",
    "#test\n",
    "#getProductInfo(\"https://www.thereformation.com/products/mylie-two-piece/1309636PAG.html?dwvar_1309636PAG_color=JUT&quantity=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ed2476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'driver.set_page_load_timeout(100)\\ndriver.set_script_timeout(100)\\n#new arrivals\\n#this can be done \\n\\ndriver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") #scrolls to bottom of page\\ndriver.get(\"https://www.thereformation.com/new\")\\n    \\ntotal_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\\ni = 1\\nwhile i < total_height:\\n    i+=10\\n    total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\\n    driver.execute_script(\"window.scrollTo(0, {});\".format(i))\\n\\n    \\nsleep(0.3)\\n\\nsoup = BeautifulSoup(driver.page_source,\\'html.parser\\')\\nprod_list = list(soup.find_all(\\'div\\',{\\'class\\':\\'product-tile__name\\'}))\\n\\nfor i in prod_list:\\n    new_arrival_names.append(i.get_text())\\n    \\n\\n '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''driver.set_page_load_timeout(100)\n",
    "driver.set_script_timeout(100)\n",
    "#new arrivals\n",
    "#this can be done \n",
    "\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") #scrolls to bottom of page\n",
    "driver.get(\"https://www.thereformation.com/new\")\n",
    "    \n",
    "total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "i = 1\n",
    "while i < total_height:\n",
    "    i+=10\n",
    "    total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "\n",
    "    \n",
    "sleep(0.3)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "prod_list = list(soup.find_all('div',{'class':'product-tile__name'}))\n",
    "\n",
    "for i in prod_list:\n",
    "    new_arrival_names.append(i.get_text())\n",
    "    \n",
    "\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5a561d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'children'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13156/712753604.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mprod_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'data-search-component'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'product-grid'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprod_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mprod_link\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'itemprop'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'children'"
     ]
    }
   ],
   "source": [
    "#getting links to crawl\n",
    "\n",
    "product_links = []\n",
    "\n",
    "driver.set_page_load_timeout(150)\n",
    "driver.set_script_timeout(150)\n",
    "\n",
    "#new arrivals\n",
    "#this can be done \n",
    "\n",
    "\n",
    "driver.get(\"https://www.thereformation.com/clothing?page=1\")\n",
    "\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") #scrolls to bottom of page\n",
    "\n",
    "total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "i = 1\n",
    "while i < total_height:\n",
    "    i+=10\n",
    "    total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "\n",
    "    \n",
    "sleep(0.3)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "sleep(1)\n",
    "#prod_list = list(soup.find('div',{'itemtype':'http://schema.org/SomeProducts%27%7D'}))\n",
    "prod_list = soup.find('div', {'data-search-component','product-grid'})\n",
    "\n",
    "for child in prod_list.children:\n",
    "    print(child)\n",
    "    prod_link = child.find('a',{'itemprop':'url'})\n",
    "    if prod_link:\n",
    "            product_links.append(\"https://thereformation.com\" + prod_link['href'])\n",
    "            print(\"https://thereformation.com\" + prod_link['href'])\n",
    "    else:\n",
    "        print(\"FAIL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all\n",
    "for link in product_links:\n",
    "    print(link)\n",
    "    getProductInfo(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe and CSV\n",
    "dataframe = pd.DataFrame(list(zip(brand, product_type, product_name, product_description, price, sales_price, color, material, product_url, picture_url, timestamp, gender, new_arrival)), columns = [\"Brand\", \"Product Type\", \"Product Name\", \"Description\", \"Price\", \"Sales Price\", \"Color\", \"Material\", \"Product URL\", \"Picture URL\", \"Timestamp\", \"Gender\", \"New Arrival\"])\n",
    "dataframe.head()\n",
    "#dataframe.to_csv('reformation.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
