{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ef5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "#\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from time import sleep\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#https://wearpact.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe3085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 102.0.5005\n",
      "Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "Driver [C:\\Users\\813ro\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe website has 6 sections (Women, Men, Baby, Kids, Bed, Bath) and we only need the first 4 as bed and bath aren't clothing\\n    All 4 have Apparel and new arrivals sections, but Women and Men have an underwear section as well\\n    This means that every catagory must be looped through, but this makes gender very easy (likely to classify baby as kids)\\n    Likely easiest to have a loop for each section (new arrivals, apparel, underwear)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization of lists\n",
    "\n",
    "brand = [] #use lowercase and replace space with '-' X\n",
    "product_type = [] #can be blank, can be extracted from url or product name X\n",
    "product_name = [] # X\n",
    "product_description = [] # X\n",
    "price = [] #original price before discount, can be blank if not on sale X\n",
    "sales_price = [] #price you pay X\n",
    "color = [] # X\n",
    "material = [] # X All clothing on the website seems to be made from organic cotton to the \n",
    "                # point the html element saying the material has cotton in the name, so all of this is Organic Cotton\n",
    "product_url = [] #url of product detail page X\n",
    "picture_url = [] #url of product image X\n",
    "timestamp = [] # current date\n",
    "gender = [] #men, women, or kids (baby and kids are grouped together for consistency) X\n",
    "new_arrival = [] #(can be blank) boolean, new -> true X\n",
    "\n",
    "new_arrival_names = {\"men\":[], \"women\":[], \"kids\":[]} #holds the names of new arrivals for checking later \n",
    "                                                        #stored as a dictionary for simplicity in calling\n",
    "current_date = date.today()\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.set_window_size(1120, 1000)\n",
    "\n",
    "\"\"\"\n",
    "The website has 6 sections (Women, Men, Baby, Kids, Bed, Bath) and we only need the first 4 as bed and bath aren't clothing\n",
    "    All 4 have Apparel and new arrivals sections, but Women and Men have an underwear section as well\n",
    "    This means that every catagory must be looped through, but this makes gender very easy (likely to classify baby as kids)\n",
    "    Likely easiest to have a loop for each section (new arrivals, apparel, underwear)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa4b8971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting info from product\n",
    "\n",
    "#everything is generated through JS on the page, therefore you cannot use beautiful soup (selenium is needed)\n",
    "def getProductInfo(url):\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    \n",
    "    \n",
    "    #brand (always pact)\n",
    "    prod_brand = \"Pact\"\n",
    "    \n",
    "    #name\n",
    "    prod_title_div = soup.find('div', {'class':'product-title'})\n",
    "    if prod_title_div == None:\n",
    "        return None\n",
    "    prod_title = prod_title_div.get_text()\n",
    "    \n",
    "    \n",
    "    #product_type + gender\n",
    "    prod_ol = soup.find('ol', {'class':'breadcrumb'})\n",
    "    \n",
    "    prod_gender = prod_ol.contents[0].get_text()\n",
    "    if prod_gender == \"baby\":\n",
    "        prod_gender = \"kids\"\n",
    "\n",
    "    prod_type = prod_ol.contents[-1].get_text()\n",
    "    \n",
    "    #prices\n",
    "    prod_price = None\n",
    "    prod_sale = soup.find('div',{'class':'dollar red'})\n",
    "    if prod_sale:\n",
    "        prod_bundle = prod_sale.get_text()\n",
    "        price_split = prod_bundle.split('$')\n",
    "        prod_price = '$' + price_split[2]\n",
    "        prod_sale_price = '$' + price_split[1]\n",
    "    else:\n",
    "        prod_sale_price = soup.find('div', {'class':'dollar'}).get_text()\n",
    "    \n",
    "    \n",
    "    #desc\n",
    "    desc_div = soup.find(\"div\", {'class':'features'})\n",
    "    desc_ul = desc_div.contents[0]\n",
    "    desc_sentence = ''\n",
    "    for child in desc_ul.children:\n",
    "        desc_sentence += child.get_text() + \". \"\n",
    "    \n",
    "    #Material (see explanation in previous cell)\n",
    "    prod_material = \"Organic Cotton\"\n",
    "    \n",
    "    #New Arrival\n",
    "    is_new = prod_title in new_arrival_names[prod_gender]\n",
    "    \n",
    "    #color + image url are unique, as they are a different entry but share almost all of the same data (including url)\n",
    "        #therefore this really makes as many entries as there are color options (using clicks from selenium)\n",
    "    color_list = soup.find('div',{'class':'product-pack-color-type'}).div.ul\n",
    "    count = 1\n",
    "    for child in color_list.children:\n",
    "        #color name\n",
    "        prod_color = child['aria-label'][6:] #takes everything past \"color \"\n",
    "        #image url (click with selenium)\n",
    "        color_btn = driver.find_element(By.XPATH, f\"//div[@class='product-pack-color-type']/div/ul/li[{count}]\")\n",
    "        \n",
    "        color_btn.click()\n",
    "        sleep(0.3)\n",
    "        image_tag = driver.find_element(By.XPATH, \"//img[@alt='product image 0']\")\n",
    "        prod_image_url = image_tag.get_attribute(\"src\")\n",
    "        count += 1\n",
    "        #creating df entry\n",
    "        timestamp.append(current_date)\n",
    "        product_url.append(url)\n",
    "        brand.append(prod_brand)\n",
    "        product_name.append(prod_title)\n",
    "        gender.append(prod_gender)\n",
    "        product_type.append(prod_type)\n",
    "        price.append(prod_price)\n",
    "        sales_price.append(prod_sale_price)\n",
    "        product_description.append(desc_sentence)\n",
    "        material.append(prod_material)\n",
    "        new_arrival.append(is_new)\n",
    "        color.append(prod_color)\n",
    "        picture_url.append(prod_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5701ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new arrivals\n",
    "#this can be done \n",
    "genders = {0:\"women\", 1:\"men\", 2:'kids', 3:'kids'}\n",
    "new_arrival_urls = (\"https://wearpact.com/women/new\", \"https://wearpact.com/men/new\", \"https://wearpact.com/baby/new\", \"https://wearpact.com/kids/new\")\n",
    "#driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") #scrolls to bottom of page\n",
    "for i in range(len(new_arrival_urls)):\n",
    "    gender_sort = genders[i]\n",
    "    driver.get(new_arrival_urls[i])\n",
    "    \n",
    "    total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    i = 1\n",
    "    while i < total_height:\n",
    "        i+=5\n",
    "        total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "    \n",
    "    sleep(0.3)\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    prod_list = soup.find('div',{'class':'product-list'})\n",
    "    for product in prod_list.children:\n",
    "        title_div = product.find('div',{'class':'card-style'})\n",
    "        if title_div:\n",
    "            new_arrival_names[gender_sort].append(title_div.get_text())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dfc832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a67db39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIL\n",
      "FAIL\n"
     ]
    }
   ],
   "source": [
    "#getting links to crawl\n",
    "urls = (\"https://wearpact.com/women\", \"https://wearpact.com/men\", \"https://wearpact.com/baby\", \"https://wearpact.com/kids\")\n",
    "product_links = []\n",
    "for section in urls:\n",
    "    driver.get(section)\n",
    "    total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    i = 1\n",
    "    while i < total_height:\n",
    "        i+=5\n",
    "        total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "    \n",
    "    sleep(0.3)\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    prod_list = soup.find('div',{'class':'product-list'})\n",
    "    for product in prod_list.children:\n",
    "        prod_link = product.find('a',{'class':'product-link'})\n",
    "        if prod_link:\n",
    "            product_links.append(\"https://wearpact.com\" + prod_link['href'])\n",
    "        else:\n",
    "            print(\"FAIL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5991ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all\n",
    "for link in product_links:\n",
    "    getProductInfo(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ee5c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe and CSV\n",
    "dataframe = pd.DataFrame(list(zip(brand, product_type, product_name, product_description, price, sales_price, color, material, product_url, picture_url, timestamp, gender, new_arrival)), columns = [\"Brand\", \"Product Type\", \"Product Name\", \"Description\", \"Price\", \"Sales Price\", \"Color\", \"Material\", \"Product URL\", \"Picture URL\", \"Timestamp\", \"Gender\", \"New Arrival\"])\n",
    "dataframe.head()\n",
    "dataframe.to_csv('wearpact.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d2d501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
